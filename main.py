#!env/bin/python3
"""
Find maalepinde in .xlsx document
"""

import re

import matplotlib
import nltk
import numpy as np
import pandas as pd
from enum import Enum
from typing import Hashable

from matplotlib import pyplot as plt
from nltk.corpus import stopwords
from pandas import DataFrame, Series

from wordCloud import word_cloud
from string import punctuation

excel_file = 'Fagtabel_Excel_2023_all.xlsx'

# Match the text in the "MÅLEPINDE" field.
# Generated by our one-and-only ChatGPT.
MAALEPIND_PATTERN = re.compile(r'\d+\.\s(.+?)\r\n\n')


class ColumnNames(Enum):
    FAGNUMMER_COLUMN_NAME: str = 'NUMMER'
    MAALEPINDE_COLUMN_NAME: str = 'MÅLPINDE'
    SCORE_COLUMN_NAME: str = 'NIVEAU'


# We use a tuple, instead of a dict,
# so the order of the subject level becomes directly tied to its location in the tuple.
# We accept the fact that lookups are likely slightly slower than they would've been in a dict.
# Order is lowest first.
LEVEL_ORDER: tuple[str, ...] = (
    '-',
    '2',
    '3',
    '4',
    'C',
    'B',
    'A',
)


def hent_maalepinde(fagnr: int) -> list[str]:
    """
    Find maalepinde for the provided fagnr in an .xlsx file.

    Currently, maalepinde for the provided fagnr across all sheets in the document,

    :param fagnr: fagnr of which the maalepinde should be found.
    :return: List of string maalepinde, stripped of \r\n\n and numberings
    """

    df: dict[str, DataFrame] = pd.read_excel(excel_file, sheet_name=None)

    # Stores all maalepinde for the provided fagnr,
    # of which we will find the ones with the higest score.
    tmp_maalepinde: list[tuple[int, str]] = []

    for sheet in df.values():

        # Find the index of our desired columns once per sheet,
        # in case sheets are formatted differently.
        # This approach should support an arbritrary number of lines above the headers.
        # But it does assert the column names in the header, and that the values come below the headers.
        fagnummer_column_idx: int = None
        maalpinde_column_idx: int = None
        score_column_idx: int = None

        row: tuple[Hashable, Series]
        for row in sheet.iterrows():

            for index, column in enumerate(row[1]):

                match column:
                    case ColumnNames.FAGNUMMER_COLUMN_NAME.value:
                        assert fagnummer_column_idx is None, \
                            'There is probably something wrong if we find our header multiple times'
                        fagnummer_column_idx = index
                    case ColumnNames.MAALEPINDE_COLUMN_NAME.value:
                        assert maalpinde_column_idx is None, \
                            'There is probably something wrong if we find our header multiple times'
                        maalpinde_column_idx = index
                    case ColumnNames.SCORE_COLUMN_NAME.value:
                        assert score_column_idx is None, \
                            'There is probably something wrong if we find our header multiple times'
                        score_column_idx = index

                if column == str(fagnr):
                    # By now, we should've found all the headers, and know the location of our columns-of-interest.
                    assert None not in {fagnummer_column_idx, maalpinde_column_idx, score_column_idx}
                    tmp_maalepinde.append((LEVEL_ORDER.index(row[1][score_column_idx]), row[1][maalpinde_column_idx]))

    # Now we want to find the 'set' of maalepinde with the highest scoring.
    best_maalepinde: str = max(tmp_maalepinde, key=(lambda maalepind_tpl: maalepind_tpl[0]))[1]

    # Use findall to extract matches
    matches = MAALEPIND_PATTERN.findall(best_maalepinde)

    nltk.download('stopwords')

    # Remove stopwords and punctuation
    def remove_stopwords(maalepind_list):
        maalpind_removed_stopwords = []
        # For fast lookups of stopwords
        stopword_set = set(stopwords.words('danish'))

        for maalepind in maalepind_list:
            # Remove punctuation
            maalepind_no_punct = ''.join(char for char in maalepind if char not in punctuation)

            # Remove stopwords
            words_without_stopwords = [word for word in maalepind_no_punct.split() if word.lower() not in stopword_set]

            # Join the words back into a sentence
            maalepind_no_stopwords = ' '.join(words_without_stopwords)

            maalpind_removed_stopwords.append(maalepind_no_stopwords)

        return maalpind_removed_stopwords

    def draw_diagram_words_used(data):
        # Extract words and their occurrences for plotting
        words_occurrences = {}
        for maalepind_no_stopwords in data:
            words = maalepind_no_stopwords.split()
            for word in words:
                if word in words_occurrences:
                    words_occurrences[word] += 1
                else:
                    words_occurrences[word] = 1

        # Get the top 10 words and their occurrences
        top_words = sorted(words_occurrences.items(), key=lambda x: x[1], reverse=True)[:10]
        words, occurrences = zip(*top_words)

        font1 = {'family': 'serif', 'color': 'black', 'size': 30}
        font2 = {'family': 'serif', 'color': 'green', 'size': 15}

        plt.barh(words, occurrences, color="darkgreen")
        plt.title("Word Occurrence", fontdict=font1)
        plt.xlabel("Occurrence", fontdict=font2)
        plt.ylabel("Words", fontdict=font2)
        plt.show()

    # Draw the diagram using the processed data
    draw_diagram_words_used(remove_stopwords(matches))


if __name__ == '__main__':

    ml = hent_maalepinde(17348)
    sw_test = hent_maalepinde(16484)

    for m in ml:
        print(m)

    for m in sw_test:
        print(m)

    word_cloud()
